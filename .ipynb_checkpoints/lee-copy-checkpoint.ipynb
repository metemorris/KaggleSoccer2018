{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Info For loading Data\n",
    "https://www.kaggle.com/dimarudov/data-analysis-using-sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/leeji/OneDrive/Documents/github-desktop/input/\"  #Insert path here\n",
    "database = path + 'database.sqlite'\n",
    "\n",
    "conn = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load att the games with home goal, away goal and betting odds for different companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25979, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_bets = pd.read_sql(\"\"\"SELECT home_team_goal, \n",
    "                                        away_team_goal,\n",
    "                                        B365H,\n",
    "                                        B365D,\n",
    "                                        B365A,\n",
    "                                        BWH,\n",
    "                                        BWD,\n",
    "                                        BWA,\n",
    "                                        IWH,\n",
    "                                        IWD,\n",
    "                                        IWA,\n",
    "                                        LBH,\n",
    "                                        LBD,\n",
    "                                        LBA,\n",
    "                                        PSH,\n",
    "                                        PSD,\n",
    "                                        PSA,\n",
    "                                        WHH,\n",
    "                                        WHD,\n",
    "                                        WHA,\n",
    "                                        VCH,\n",
    "                                        VCD,\n",
    "                                        VCA,\n",
    "                                        GBH,\n",
    "                                        GBD,\n",
    "                                        GBA,\n",
    "                                        BSH,\n",
    "                                        BSD,\n",
    "                                        BSA\n",
    "                                        \n",
    "                                        \n",
    "                                FROM Match;\"\"\", conn)\n",
    "\n",
    "detailed_bets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check all the columns and see if there are lots of NaNs, we noticed that certain betting companies have lots of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping GB, BS, and PS betting companies because they have lots of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_bets_filtered = pd.read_sql(\"\"\"SELECT home_team_goal, \n",
    "                                        away_team_goal,\n",
    "                                        B365H,\n",
    "                                        B365D,\n",
    "                                        B365A,\n",
    "                                        BWH,\n",
    "                                        BWD,\n",
    "                                        BWA,\n",
    "                                        IWH,\n",
    "                                        IWD,\n",
    "                                        IWA,\n",
    "                                        LBH,\n",
    "                                        LBD,\n",
    "                                        LBA,\n",
    "                                        WHH,\n",
    "                                        WHD,\n",
    "                                        WHA,\n",
    "                                        VCH,\n",
    "                                        VCD,\n",
    "                                        VCA\n",
    "                                        \n",
    "                                        \n",
    "                                FROM Match;\"\"\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop all the matches that have lots of naans and get 17 000 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22432, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_bets = detailed_bets_filtered.dropna(thresh=20) #drops vals if there are more than 1 Nan\n",
    "\n",
    "cleaned_bets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>...</th>\n",
       "      <th>LBH</th>\n",
       "      <th>LBD</th>\n",
       "      <th>LBA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.65</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.60</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.65</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.85</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.35</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.25</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.33</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.35</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>5.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.55</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.55</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.75</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.80</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24527</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24528</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24529</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24530</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24531</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24532</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24533</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24534</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24535</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.45</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.30</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24536</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24537</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>8.25</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>9.50</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24538</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24539</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24541</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>12.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>9.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>13.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24542</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.05</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24543</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.40</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24544</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24545</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24546</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24547</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>10.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>10.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>11.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24548</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.33</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.60</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24549</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24550</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>...</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24551</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24552</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.30</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24553</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24554</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24555</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24556</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22432 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       home_team_goal  away_team_goal  B365H  B365D  B365A   BWH    BWD  \\\n",
       "0                   1               1   1.73   3.40   5.00  1.75   3.35   \n",
       "1                   0               0   1.95   3.20   3.60  1.80   3.30   \n",
       "2                   0               3   2.38   3.30   2.75  2.40   3.30   \n",
       "3                   5               0   1.44   3.75   7.50  1.40   4.00   \n",
       "4                   1               3   5.00   3.50   1.65  5.00   3.50   \n",
       "5                   1               1   4.75   3.40   1.67  4.85   3.40   \n",
       "6                   2               2   2.10   3.20   3.30  2.05   3.25   \n",
       "7                   1               2   3.20   3.40   2.20  2.55   3.30   \n",
       "8                   1               0   2.25   3.25   2.88  2.30   3.25   \n",
       "9                   4               1   1.30   5.25   9.50  1.25   5.00   \n",
       "10                  1               2   1.30   5.25   9.50  1.25   5.00   \n",
       "11                  0               2   2.60   3.20   2.50  2.60   3.20   \n",
       "12                  0               0   1.91   3.40   4.00  1.85   3.35   \n",
       "13                  2               2   2.90   3.30   2.38  2.75   3.30   \n",
       "14                  1               2   1.70   3.30   4.50  1.75   3.45   \n",
       "15                  0               1   2.35   3.30   3.00  2.35   3.25   \n",
       "16                  1               3   6.00   3.75   1.57  5.10   3.60   \n",
       "17                  1               3   4.00   3.25   1.83  4.30   3.50   \n",
       "18                  2               3   1.36   4.75   8.50  1.25   5.00   \n",
       "19                  0               0   2.40   3.30   2.90  2.25   3.20   \n",
       "20                  2               2   3.20   3.30   2.25  3.25   3.20   \n",
       "21                  2               0   1.75   3.75   4.33  1.85   3.35   \n",
       "22                  1               1   1.40   4.33   8.00  1.38   4.00   \n",
       "23                  1               2   1.83   3.50   4.20  1.80   3.35   \n",
       "24                  0               0   2.00   3.50   3.60  1.95   3.25   \n",
       "25                  1               0   2.70   3.25   2.60  2.50   3.30   \n",
       "26                  1               3   3.60   3.30   2.05  3.40   3.25   \n",
       "27                  1               1   2.30   3.25   2.90  2.20   3.15   \n",
       "28                  1               1   1.25   5.25  10.00  1.23   5.00   \n",
       "29                  2               2   2.00   3.25   3.50  2.10   3.20   \n",
       "...               ...             ...    ...    ...    ...   ...    ...   \n",
       "24527               2               1   4.00   3.60   1.91  4.20   3.50   \n",
       "24528               0               2   2.10   3.30   3.75  2.10   3.00   \n",
       "24529               0               0   1.44   4.50   7.50  1.50   4.10   \n",
       "24530               1               0   4.33   3.40   1.91  4.40   3.50   \n",
       "24531               1               1   3.20   3.30   2.30  3.10   3.10   \n",
       "24532               3               1   2.38   3.10   3.30  2.40   3.10   \n",
       "24533               3               1   2.30   3.30   3.20  2.30   3.40   \n",
       "24534               1               1   2.60   3.20   2.80  2.60   3.00   \n",
       "24535               1               2   2.00   3.30   4.00  2.00   3.20   \n",
       "24536               0               2   2.20   3.50   3.20  2.10   3.40   \n",
       "24537               5               2   1.14   9.00  15.00  1.17   8.25   \n",
       "24538               1               1   3.60   3.40   2.10  3.40   3.30   \n",
       "24539               4               0   2.15   3.20   3.60  2.15   3.10   \n",
       "24540               1               2   2.00   3.50   3.75  2.05   3.40   \n",
       "24541               3               0   1.08  12.00  23.00  1.10  10.50   \n",
       "24542               0               2   4.00   3.20   2.05  3.70   3.25   \n",
       "24543               3               0   1.62   3.75   6.00  1.65   3.80   \n",
       "24544               2               2   2.70   3.10   2.80  2.75   2.95   \n",
       "24545               3               3   2.00   3.20   4.20  2.05   3.20   \n",
       "24546               1               3   2.00   3.30   4.00  2.10   3.20   \n",
       "24547               3               1   1.11  10.00  19.00  1.11   9.50   \n",
       "24548               5               0   1.44   4.33   8.00  1.48   4.33   \n",
       "24549               0               0   3.50   3.25   2.20  3.25   3.25   \n",
       "24550               1               3   3.80   3.80   1.91  3.90   3.90   \n",
       "24551               0               4   2.63   3.20   2.80  2.70   3.00   \n",
       "24552               2               1   1.57   3.80   6.50  1.57   4.00   \n",
       "24553               2               0   2.25   3.25   3.40  2.35   3.10   \n",
       "24554               3               0   1.53   4.00   7.00  1.55   4.00   \n",
       "24555               1               1   2.30   3.25   3.25  2.35   3.25   \n",
       "24556               3               0   2.20   3.40   3.20  2.25   3.50   \n",
       "\n",
       "         BWA   IWH   IWD   ...     LBH    LBD    LBA   WHH   WHD    WHA   VCH  \\\n",
       "0       4.20  1.85  3.20   ...    1.80   3.30   3.75  1.70  3.30   4.33  1.65   \n",
       "1       3.95  1.90  3.20   ...    1.90   3.20   3.50  1.83  3.30   3.60  2.00   \n",
       "2       2.55  2.60  3.10   ...    2.50   3.20   2.50  2.50  3.25   2.40  2.35   \n",
       "3       6.80  1.40  3.90   ...    1.44   3.60   6.50  1.44  3.75   6.00  1.45   \n",
       "4       1.60  4.00  3.30   ...    4.00   3.40   1.72  4.20  3.40   1.70  4.50   \n",
       "5       1.65  3.70  3.20   ...    5.00   3.25   1.62  4.20  3.40   1.70  4.35   \n",
       "6       3.15  1.85  3.20   ...    1.83   3.30   3.60  1.83  3.30   3.60  2.10   \n",
       "7       2.40  2.40  3.20   ...    2.50   3.20   2.50  2.70  3.25   2.25  2.80   \n",
       "8       2.70  2.10  3.10   ...    2.25   3.20   2.75  2.20  3.25   2.75  2.25   \n",
       "9      10.00  1.30  4.20   ...    1.25   4.50  10.00  1.35  4.20   7.00  1.30   \n",
       "10     10.00  1.30  4.20   ...    1.29   4.33   9.00  1.25  4.50   9.50  1.28   \n",
       "11      2.40  2.40  3.20   ...    2.50   3.20   2.50  2.60  3.10   2.40  2.65   \n",
       "12      3.80  1.80  3.10   ...    1.80   3.30   3.75  1.80  3.30   3.75  2.00   \n",
       "13      2.25  2.50  3.20   ...    2.60   3.20   2.38  2.75  3.20   2.25  2.75   \n",
       "14      4.00  1.70  3.20   ...    1.67   3.30   4.50  1.70  3.40   4.20  1.70   \n",
       "15      2.70  2.20  3.10   ...    2.20   3.20   2.80  2.20  3.20   2.80  2.20   \n",
       "16      1.55  4.60  3.40   ...    5.50   3.60   1.50  5.25  3.50   1.55  5.50   \n",
       "17      1.68  3.70  3.20   ...    4.00   3.40   1.73  4.00  3.30   1.75  3.60   \n",
       "18      9.00  1.30  4.20   ...    1.36   4.00   7.00  1.30  4.20   8.50  1.28   \n",
       "19      2.80  2.20  3.10   ...    2.50   3.20   2.50  2.30  3.25   2.60  2.35   \n",
       "20      2.10  3.10  3.00   ...    2.75   3.25   2.20  3.00  3.20   2.10  3.25   \n",
       "21      3.65  1.75  3.20   ...    1.73   3.40   4.00  1.80  3.40   3.60  1.75   \n",
       "22      7.20  1.40  3.90   ...    1.33   4.00   8.00  1.40  4.00   7.00  1.35   \n",
       "23      3.90  1.85  3.20   ...    1.73   3.40   4.00  1.90  3.40   3.25  1.80   \n",
       "24      3.40  2.00  3.20   ...    1.91   3.25   3.40  2.05  3.25   3.00  2.00   \n",
       "25      2.45  2.45  3.10   ...    2.50   3.20   2.50  2.50  3.25   2.40  2.40   \n",
       "26      1.95  3.90  3.30   ...    3.75   3.30   1.80  3.25  3.25   1.95  3.75   \n",
       "27      3.00  2.00  3.10   ...    2.20   3.25   2.75  2.15  3.10   3.00  2.25   \n",
       "28     10.00  1.30  4.20   ...    1.25   4.50  10.00  1.25  4.80   9.00  1.25   \n",
       "29      3.20  2.00  3.10   ...    2.00   3.20   3.20  1.90  3.25   3.50  2.10   \n",
       "...      ...   ...   ...   ...     ...    ...    ...   ...   ...    ...   ...   \n",
       "24527   1.90  3.50  3.40   ...    3.80   3.80   1.85  4.33  3.10   1.95  4.10   \n",
       "24528   3.80  2.10  3.30   ...    2.00   3.20   3.80  2.10  3.20   3.75  2.05   \n",
       "24529   6.25  1.55  4.00   ...    1.50   4.33   6.50  1.50  4.00   7.00  1.50   \n",
       "24530   1.85  4.20  3.50   ...    4.20   3.30   1.91  4.33  3.10   1.95  4.40   \n",
       "24531   2.45  2.75  3.20   ...    3.00   3.25   2.30  2.90  3.10   2.50  3.13   \n",
       "24532   3.00  2.40  3.30   ...    2.30   3.10   3.20  2.40  3.10   3.10  2.40   \n",
       "24533   3.20  2.30  3.30   ...    2.30   3.20   3.10  2.40  3.10   3.10  2.38   \n",
       "24534   2.85  2.60  3.20   ...    2.50   3.10   2.80  2.62  3.10   2.80  2.63   \n",
       "24535   3.90  1.90  3.45   ...    1.95   3.25   4.00  2.05  3.10   4.00  2.00   \n",
       "24536   3.30  2.20  3.20   ...    2.10   3.60   3.25  2.15  3.50   3.20  2.20   \n",
       "24537  13.50  1.17  6.50   ...    1.14   8.50  17.00  1.17  7.00  17.00  1.15   \n",
       "24538   2.20  3.20  3.20   ...    3.50   3.30   2.05  3.50  3.10   2.20  3.60   \n",
       "24539   3.60  2.10  3.30   ...    2.10   3.10   3.60  2.20  3.10   3.50  2.20   \n",
       "24540   3.50  2.00  3.30   ...    2.00   3.40   3.60  2.10  3.20   3.75  2.05   \n",
       "24541  23.00  1.07  9.50   ...    1.10  10.00  26.00  1.10  9.00  26.00  1.08   \n",
       "24542   2.10  3.30  3.30   ...    4.00   3.10   2.00  4.20  3.00   2.05  4.30   \n",
       "24543   5.50  1.60  3.70   ...    1.62   3.80   5.50  1.67  3.40   6.00  1.62   \n",
       "24544   2.90  2.60  3.20   ...    2.62   3.00   2.75  2.70  3.00   2.80  2.70   \n",
       "24545   3.70  2.10  3.10   ...    1.95   3.25   4.00  2.05  3.10   4.00  2.00   \n",
       "24546   3.60  2.00  3.30   ...    2.00   3.25   3.80  2.10  3.20   3.75  2.05   \n",
       "24547  21.00  1.10  8.00   ...    1.11  10.00  21.00  1.14  7.00  21.00  1.11   \n",
       "24548   7.00  1.50  4.00   ...    1.44   4.20   7.00  1.50  4.00   7.00  1.50   \n",
       "24549   2.20  3.30  3.30   ...    3.50   3.25   2.10  3.50  3.10   2.20  3.60   \n",
       "24550   1.95  3.80  3.60   ...    3.60   3.80   1.85  3.75  3.50   1.95  3.90   \n",
       "24551   2.75  2.60  3.20   ...    2.62   2.90   2.80  2.70  3.10   2.70  2.75   \n",
       "24552   6.50  1.65  3.70   ...    1.57   3.75   6.50  1.62  3.30   7.00  1.57   \n",
       "24553   3.10  2.20  3.20   ...    2.25   3.20   3.25  2.38  3.10   3.10  2.30   \n",
       "24554   6.50  1.60  3.70   ...    1.50   4.00   6.50  1.57  3.50   7.00  1.55   \n",
       "24555   3.00  2.40  3.30   ...    2.30   3.20   3.10  2.40  3.10   3.10  2.30   \n",
       "24556   3.20  2.30  3.30   ...    2.10   3.40   3.30  2.20  3.40   3.20  2.20   \n",
       "\n",
       "         VCD    VCA  result  \n",
       "0       3.40   4.50       0  \n",
       "1       3.25   3.25       0  \n",
       "2       3.25   2.65      -1  \n",
       "3       3.75   6.50       1  \n",
       "4       3.40   1.65      -1  \n",
       "5       3.40   1.70       0  \n",
       "6       3.25   3.00       0  \n",
       "7       3.25   2.25      -1  \n",
       "8       3.25   2.80       1  \n",
       "9       4.35   8.50       1  \n",
       "10      4.50   8.50      -1  \n",
       "11      3.30   2.30      -1  \n",
       "12      3.20   3.40       0  \n",
       "13      3.20   2.30       0  \n",
       "14      3.40   4.35      -1  \n",
       "15      3.25   2.90      -1  \n",
       "16      3.50   1.55      -1  \n",
       "17      3.25   1.90      -1  \n",
       "18      4.50   8.50      -1  \n",
       "19      3.25   2.65       0  \n",
       "20      3.25   2.00       0  \n",
       "21      3.25   4.35       1  \n",
       "22      4.00   7.50       0  \n",
       "23      3.25   4.00      -1  \n",
       "24      3.25   3.25       0  \n",
       "25      3.25   2.60       1  \n",
       "26      3.25   1.85      -1  \n",
       "27      3.10   2.80       0  \n",
       "28      5.00   9.00       0  \n",
       "29      3.30   3.10       0  \n",
       "...      ...    ...     ...  \n",
       "24527   3.90   1.91       1  \n",
       "24528   3.40   4.10      -1  \n",
       "24529   4.50   7.50       0  \n",
       "24530   3.60   1.93       1  \n",
       "24531   3.40   2.45       0  \n",
       "24532   3.25   3.30       1  \n",
       "24533   3.40   3.25       1  \n",
       "24534   3.25   3.00       0  \n",
       "24535   3.40   4.30      -1  \n",
       "24536   3.80   3.30      -1  \n",
       "24537   9.50  19.00       1  \n",
       "24538   3.50   2.20       0  \n",
       "24539   3.30   3.75       1  \n",
       "24540   3.70   3.75      -1  \n",
       "24541  13.00  34.00       1  \n",
       "24542   3.30   2.05      -1  \n",
       "24543   4.10   6.25       1  \n",
       "24544   3.25   2.88       0  \n",
       "24545   3.40   4.33       0  \n",
       "24546   3.50   4.00      -1  \n",
       "24547  11.00  31.00       1  \n",
       "24548   4.60   7.50       1  \n",
       "24549   3.40   2.20       0  \n",
       "24550   4.00   1.93      -1  \n",
       "24551   3.13   2.90      -1  \n",
       "24552   4.00   7.00       1  \n",
       "24553   3.40   3.40       1  \n",
       "24554   4.20   7.00       1  \n",
       "24555   3.40   3.30       0  \n",
       "24556   3.60   3.50       1  \n",
       "\n",
       "[22432 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_bets['result'] = 0\n",
    "cleaned_bets.loc[detailed_bets['home_team_goal'] < detailed_bets['away_team_goal'], 'result'] = -1\n",
    "cleaned_bets.loc[detailed_bets['home_team_goal'] > detailed_bets['away_team_goal'], 'result'] = 1\n",
    "cleaned_bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets_percentage = cleaned_bets[cleaned_bets.columns[2:20]] #take all the COLUMNS and take the reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>IWA</th>\n",
       "      <th>LBH</th>\n",
       "      <th>LBD</th>\n",
       "      <th>LBA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.578035</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.578035</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.578035</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.546448</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.578035</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.322581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24527</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.523560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24528</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.243902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24529</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24530</th>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.518135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24531</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24532</th>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24533</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24534</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.380228</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24535</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24536</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24537</th>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24538</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24539</th>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24541</th>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24542</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.487805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24543</th>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24544</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.347222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24545</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.230947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24546</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24547</th>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24548</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24549</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24550</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.518135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24551</th>\n",
       "      <td>0.380228</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24552</th>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24553</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24554</th>\n",
       "      <td>0.653595</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24555</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24556</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22432 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          B365H     B365D     B365A       BWH       BWD       BWA       IWH  \\\n",
       "0      0.578035  0.294118  0.200000  0.571429  0.298507  0.238095  0.540541   \n",
       "1      0.512821  0.312500  0.277778  0.555556  0.303030  0.253165  0.526316   \n",
       "2      0.420168  0.303030  0.363636  0.416667  0.303030  0.392157  0.384615   \n",
       "3      0.694444  0.266667  0.133333  0.714286  0.250000  0.147059  0.714286   \n",
       "4      0.200000  0.285714  0.606061  0.200000  0.285714  0.625000  0.250000   \n",
       "5      0.210526  0.294118  0.598802  0.206186  0.294118  0.606061  0.270270   \n",
       "6      0.476190  0.312500  0.303030  0.487805  0.307692  0.317460  0.540541   \n",
       "7      0.312500  0.294118  0.454545  0.392157  0.303030  0.416667  0.416667   \n",
       "8      0.444444  0.307692  0.347222  0.434783  0.307692  0.370370  0.476190   \n",
       "9      0.769231  0.190476  0.105263  0.800000  0.200000  0.100000  0.769231   \n",
       "10     0.769231  0.190476  0.105263  0.800000  0.200000  0.100000  0.769231   \n",
       "11     0.384615  0.312500  0.400000  0.384615  0.312500  0.416667  0.416667   \n",
       "12     0.523560  0.294118  0.250000  0.540541  0.298507  0.263158  0.555556   \n",
       "13     0.344828  0.303030  0.420168  0.363636  0.303030  0.444444  0.400000   \n",
       "14     0.588235  0.303030  0.222222  0.571429  0.289855  0.250000  0.588235   \n",
       "15     0.425532  0.303030  0.333333  0.425532  0.307692  0.370370  0.454545   \n",
       "16     0.166667  0.266667  0.636943  0.196078  0.277778  0.645161  0.217391   \n",
       "17     0.250000  0.307692  0.546448  0.232558  0.285714  0.595238  0.270270   \n",
       "18     0.735294  0.210526  0.117647  0.800000  0.200000  0.111111  0.769231   \n",
       "19     0.416667  0.303030  0.344828  0.444444  0.312500  0.357143  0.454545   \n",
       "20     0.312500  0.303030  0.444444  0.307692  0.312500  0.476190  0.322581   \n",
       "21     0.571429  0.266667  0.230947  0.540541  0.298507  0.273973  0.571429   \n",
       "22     0.714286  0.230947  0.125000  0.724638  0.250000  0.138889  0.714286   \n",
       "23     0.546448  0.285714  0.238095  0.555556  0.298507  0.256410  0.540541   \n",
       "24     0.500000  0.285714  0.277778  0.512821  0.307692  0.294118  0.500000   \n",
       "25     0.370370  0.307692  0.384615  0.400000  0.303030  0.408163  0.408163   \n",
       "26     0.277778  0.303030  0.487805  0.294118  0.307692  0.512821  0.256410   \n",
       "27     0.434783  0.307692  0.344828  0.454545  0.317460  0.333333  0.500000   \n",
       "28     0.800000  0.190476  0.100000  0.813008  0.200000  0.100000  0.769231   \n",
       "29     0.500000  0.307692  0.285714  0.476190  0.312500  0.312500  0.500000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24527  0.250000  0.277778  0.523560  0.238095  0.285714  0.526316  0.285714   \n",
       "24528  0.476190  0.303030  0.266667  0.476190  0.333333  0.263158  0.476190   \n",
       "24529  0.694444  0.222222  0.133333  0.666667  0.243902  0.160000  0.645161   \n",
       "24530  0.230947  0.294118  0.523560  0.227273  0.285714  0.540541  0.238095   \n",
       "24531  0.312500  0.303030  0.434783  0.322581  0.322581  0.408163  0.363636   \n",
       "24532  0.420168  0.322581  0.303030  0.416667  0.322581  0.333333  0.416667   \n",
       "24533  0.434783  0.303030  0.312500  0.434783  0.294118  0.312500  0.434783   \n",
       "24534  0.384615  0.312500  0.357143  0.384615  0.333333  0.350877  0.384615   \n",
       "24535  0.500000  0.303030  0.250000  0.500000  0.312500  0.256410  0.526316   \n",
       "24536  0.454545  0.285714  0.312500  0.476190  0.294118  0.303030  0.454545   \n",
       "24537  0.877193  0.111111  0.066667  0.854701  0.121212  0.074074  0.854701   \n",
       "24538  0.277778  0.294118  0.476190  0.294118  0.303030  0.454545  0.312500   \n",
       "24539  0.465116  0.312500  0.277778  0.465116  0.322581  0.277778  0.476190   \n",
       "24540  0.500000  0.285714  0.266667  0.487805  0.294118  0.285714  0.500000   \n",
       "24541  0.925926  0.083333  0.043478  0.909091  0.095238  0.043478  0.934579   \n",
       "24542  0.250000  0.312500  0.487805  0.270270  0.307692  0.476190  0.303030   \n",
       "24543  0.617284  0.266667  0.166667  0.606061  0.263158  0.181818  0.625000   \n",
       "24544  0.370370  0.322581  0.357143  0.363636  0.338983  0.344828  0.384615   \n",
       "24545  0.500000  0.312500  0.238095  0.487805  0.312500  0.270270  0.476190   \n",
       "24546  0.500000  0.303030  0.250000  0.476190  0.312500  0.277778  0.500000   \n",
       "24547  0.900901  0.100000  0.052632  0.900901  0.105263  0.047619  0.909091   \n",
       "24548  0.694444  0.230947  0.125000  0.675676  0.230947  0.142857  0.666667   \n",
       "24549  0.285714  0.307692  0.454545  0.307692  0.307692  0.454545  0.303030   \n",
       "24550  0.263158  0.263158  0.523560  0.256410  0.256410  0.512821  0.263158   \n",
       "24551  0.380228  0.312500  0.357143  0.370370  0.333333  0.363636  0.384615   \n",
       "24552  0.636943  0.263158  0.153846  0.636943  0.250000  0.153846  0.606061   \n",
       "24553  0.444444  0.307692  0.294118  0.425532  0.322581  0.322581  0.454545   \n",
       "24554  0.653595  0.250000  0.142857  0.645161  0.250000  0.153846  0.625000   \n",
       "24555  0.434783  0.307692  0.307692  0.425532  0.307692  0.333333  0.416667   \n",
       "24556  0.454545  0.294118  0.312500  0.444444  0.285714  0.312500  0.434783   \n",
       "\n",
       "            IWD       IWA       LBH       LBD       LBA       WHH       WHD  \\\n",
       "0      0.312500  0.285714  0.555556  0.303030  0.266667  0.588235  0.303030   \n",
       "1      0.312500  0.285714  0.526316  0.312500  0.285714  0.546448  0.303030   \n",
       "2      0.322581  0.434783  0.400000  0.312500  0.400000  0.400000  0.307692   \n",
       "3      0.256410  0.166667  0.694444  0.277778  0.153846  0.694444  0.266667   \n",
       "4      0.303030  0.588235  0.250000  0.294118  0.581395  0.238095  0.294118   \n",
       "5      0.312500  0.555556  0.200000  0.307692  0.617284  0.238095  0.294118   \n",
       "6      0.312500  0.285714  0.546448  0.303030  0.277778  0.546448  0.303030   \n",
       "7      0.312500  0.416667  0.400000  0.312500  0.400000  0.370370  0.307692   \n",
       "8      0.322581  0.333333  0.444444  0.312500  0.363636  0.454545  0.307692   \n",
       "9      0.238095  0.125000  0.800000  0.222222  0.100000  0.740741  0.238095   \n",
       "10     0.238095  0.125000  0.775194  0.230947  0.111111  0.800000  0.222222   \n",
       "11     0.312500  0.416667  0.400000  0.312500  0.400000  0.384615  0.322581   \n",
       "12     0.322581  0.263158  0.555556  0.303030  0.266667  0.555556  0.303030   \n",
       "13     0.312500  0.434783  0.384615  0.312500  0.420168  0.363636  0.312500   \n",
       "14     0.312500  0.238095  0.598802  0.303030  0.222222  0.588235  0.294118   \n",
       "15     0.322581  0.357143  0.454545  0.312500  0.357143  0.454545  0.312500   \n",
       "16     0.294118  0.625000  0.181818  0.277778  0.666667  0.190476  0.285714   \n",
       "17     0.312500  0.555556  0.250000  0.294118  0.578035  0.250000  0.303030   \n",
       "18     0.238095  0.125000  0.735294  0.250000  0.142857  0.769231  0.238095   \n",
       "19     0.322581  0.357143  0.400000  0.312500  0.400000  0.434783  0.307692   \n",
       "20     0.333333  0.476190  0.363636  0.307692  0.454545  0.333333  0.312500   \n",
       "21     0.312500  0.250000  0.578035  0.294118  0.250000  0.555556  0.294118   \n",
       "22     0.256410  0.166667  0.751880  0.250000  0.125000  0.714286  0.250000   \n",
       "23     0.312500  0.285714  0.578035  0.294118  0.250000  0.526316  0.294118   \n",
       "24     0.312500  0.322581  0.523560  0.307692  0.294118  0.487805  0.307692   \n",
       "25     0.322581  0.408163  0.400000  0.312500  0.400000  0.400000  0.307692   \n",
       "26     0.303030  0.571429  0.266667  0.303030  0.555556  0.307692  0.307692   \n",
       "27     0.322581  0.312500  0.454545  0.307692  0.363636  0.465116  0.322581   \n",
       "28     0.238095  0.125000  0.800000  0.222222  0.100000  0.800000  0.208333   \n",
       "29     0.322581  0.312500  0.500000  0.312500  0.312500  0.526316  0.307692   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24527  0.294118  0.500000  0.263158  0.263158  0.540541  0.230947  0.322581   \n",
       "24528  0.303030  0.303030  0.500000  0.312500  0.263158  0.476190  0.312500   \n",
       "24529  0.250000  0.181818  0.666667  0.230947  0.153846  0.666667  0.250000   \n",
       "24530  0.285714  0.555556  0.238095  0.303030  0.523560  0.230947  0.322581   \n",
       "24531  0.312500  0.400000  0.333333  0.307692  0.434783  0.344828  0.322581   \n",
       "24532  0.303030  0.363636  0.434783  0.322581  0.312500  0.416667  0.322581   \n",
       "24533  0.303030  0.344828  0.434783  0.312500  0.322581  0.416667  0.322581   \n",
       "24534  0.312500  0.384615  0.400000  0.322581  0.357143  0.381679  0.322581   \n",
       "24535  0.289855  0.263158  0.512821  0.307692  0.250000  0.487805  0.322581   \n",
       "24536  0.312500  0.312500  0.476190  0.277778  0.307692  0.465116  0.285714   \n",
       "24537  0.153846  0.071429  0.877193  0.117647  0.058824  0.854701  0.142857   \n",
       "24538  0.312500  0.454545  0.285714  0.303030  0.487805  0.285714  0.322581   \n",
       "24539  0.303030  0.303030  0.476190  0.322581  0.277778  0.454545  0.322581   \n",
       "24540  0.303030  0.277778  0.500000  0.294118  0.277778  0.476190  0.312500   \n",
       "24541  0.105263  0.045455  0.909091  0.100000  0.038462  0.909091  0.111111   \n",
       "24542  0.303030  0.476190  0.250000  0.322581  0.500000  0.238095  0.333333   \n",
       "24543  0.270270  0.185185  0.617284  0.263158  0.181818  0.598802  0.294118   \n",
       "24544  0.312500  0.384615  0.381679  0.333333  0.363636  0.370370  0.333333   \n",
       "24545  0.322581  0.285714  0.512821  0.307692  0.250000  0.487805  0.322581   \n",
       "24546  0.303030  0.277778  0.500000  0.307692  0.263158  0.476190  0.312500   \n",
       "24547  0.125000  0.050000  0.900901  0.100000  0.047619  0.877193  0.142857   \n",
       "24548  0.250000  0.163934  0.694444  0.238095  0.142857  0.666667  0.250000   \n",
       "24549  0.303030  0.476190  0.285714  0.307692  0.476190  0.285714  0.322581   \n",
       "24550  0.277778  0.540541  0.277778  0.263158  0.540541  0.266667  0.285714   \n",
       "24551  0.312500  0.384615  0.381679  0.344828  0.357143  0.370370  0.322581   \n",
       "24552  0.270270  0.204082  0.636943  0.266667  0.153846  0.617284  0.303030   \n",
       "24553  0.312500  0.312500  0.444444  0.312500  0.307692  0.420168  0.322581   \n",
       "24554  0.270270  0.185185  0.666667  0.250000  0.153846  0.636943  0.285714   \n",
       "24555  0.303030  0.363636  0.434783  0.312500  0.322581  0.416667  0.322581   \n",
       "24556  0.303030  0.344828  0.476190  0.294118  0.303030  0.454545  0.294118   \n",
       "\n",
       "            WHA       VCH       VCD       VCA  \n",
       "0      0.230947  0.606061  0.294118  0.222222  \n",
       "1      0.277778  0.500000  0.307692  0.307692  \n",
       "2      0.416667  0.425532  0.307692  0.377358  \n",
       "3      0.166667  0.689655  0.266667  0.153846  \n",
       "4      0.588235  0.222222  0.294118  0.606061  \n",
       "5      0.588235  0.229885  0.294118  0.588235  \n",
       "6      0.277778  0.476190  0.307692  0.333333  \n",
       "7      0.444444  0.357143  0.307692  0.444444  \n",
       "8      0.363636  0.444444  0.307692  0.357143  \n",
       "9      0.142857  0.769231  0.229885  0.117647  \n",
       "10     0.105263  0.781250  0.222222  0.117647  \n",
       "11     0.416667  0.377358  0.303030  0.434783  \n",
       "12     0.266667  0.500000  0.312500  0.294118  \n",
       "13     0.444444  0.363636  0.312500  0.434783  \n",
       "14     0.238095  0.588235  0.294118  0.229885  \n",
       "15     0.357143  0.454545  0.307692  0.344828  \n",
       "16     0.645161  0.181818  0.285714  0.645161  \n",
       "17     0.571429  0.277778  0.307692  0.526316  \n",
       "18     0.117647  0.781250  0.222222  0.117647  \n",
       "19     0.384615  0.425532  0.307692  0.377358  \n",
       "20     0.476190  0.307692  0.307692  0.500000  \n",
       "21     0.277778  0.571429  0.307692  0.229885  \n",
       "22     0.142857  0.740741  0.250000  0.133333  \n",
       "23     0.307692  0.555556  0.307692  0.250000  \n",
       "24     0.333333  0.500000  0.307692  0.307692  \n",
       "25     0.416667  0.416667  0.307692  0.384615  \n",
       "26     0.512821  0.266667  0.307692  0.540541  \n",
       "27     0.333333  0.444444  0.322581  0.357143  \n",
       "28     0.111111  0.800000  0.200000  0.111111  \n",
       "29     0.285714  0.476190  0.303030  0.322581  \n",
       "...         ...       ...       ...       ...  \n",
       "24527  0.512821  0.243902  0.256410  0.523560  \n",
       "24528  0.266667  0.487805  0.294118  0.243902  \n",
       "24529  0.142857  0.666667  0.222222  0.133333  \n",
       "24530  0.512821  0.227273  0.277778  0.518135  \n",
       "24531  0.400000  0.319489  0.294118  0.408163  \n",
       "24532  0.322581  0.416667  0.307692  0.303030  \n",
       "24533  0.322581  0.420168  0.294118  0.307692  \n",
       "24534  0.357143  0.380228  0.307692  0.333333  \n",
       "24535  0.250000  0.500000  0.294118  0.232558  \n",
       "24536  0.312500  0.454545  0.263158  0.303030  \n",
       "24537  0.058824  0.869565  0.105263  0.052632  \n",
       "24538  0.454545  0.277778  0.285714  0.454545  \n",
       "24539  0.285714  0.454545  0.303030  0.266667  \n",
       "24540  0.266667  0.487805  0.270270  0.266667  \n",
       "24541  0.038462  0.925926  0.076923  0.029412  \n",
       "24542  0.487805  0.232558  0.303030  0.487805  \n",
       "24543  0.166667  0.617284  0.243902  0.160000  \n",
       "24544  0.357143  0.370370  0.307692  0.347222  \n",
       "24545  0.250000  0.500000  0.294118  0.230947  \n",
       "24546  0.266667  0.487805  0.285714  0.250000  \n",
       "24547  0.047619  0.900901  0.090909  0.032258  \n",
       "24548  0.142857  0.666667  0.217391  0.133333  \n",
       "24549  0.454545  0.277778  0.294118  0.454545  \n",
       "24550  0.512821  0.256410  0.250000  0.518135  \n",
       "24551  0.370370  0.363636  0.319489  0.344828  \n",
       "24552  0.142857  0.636943  0.250000  0.142857  \n",
       "24553  0.322581  0.434783  0.294118  0.294118  \n",
       "24554  0.142857  0.645161  0.238095  0.142857  \n",
       "24555  0.322581  0.434783  0.294118  0.303030  \n",
       "24556  0.312500  0.454545  0.277778  0.285714  \n",
       "\n",
       "[22432 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bets_percentage.rdiv(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B365H',\n",
       " 'B365D',\n",
       " 'B365A',\n",
       " 'BWH',\n",
       " 'BWD',\n",
       " 'BWA',\n",
       " 'IWH',\n",
       " 'IWD',\n",
       " 'IWA',\n",
       " 'LBH',\n",
       " 'LBD',\n",
       " 'LBA',\n",
       " 'WHH',\n",
       " 'WHD',\n",
       " 'WHA',\n",
       " 'VCH',\n",
       " 'VCD',\n",
       " 'VCA']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bets_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win = bets_percentage.iloc[:,0:18:3]\n",
    "away_win = bets_percentage.iloc[:,2:18:3]\n",
    "draw = bets_percentage.iloc[:,1:18:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try plotting the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win = bets_percentage.rdiv(1).iloc[:,0:18:3]\n",
    "away_win = bets_percentage.rdiv(1).iloc[:,2:18:3]\n",
    "draw = bets_percentage.rdiv(1).iloc[:,1:18:3]\n",
    "y = cleaned_bets['result'] # actual match outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c1fa516f4d1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhome_win\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "arrays = [home_win, away_win, draw]\n",
    "names = ['Home Win', 'Away Win' , 'Draw']\n",
    "\n",
    "for array, name in zip(arrays, names): \n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    corr = array.corr()\n",
    "    sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax, linewidths=.5,  vmin=0.95, vmax=1)\n",
    "    plt.title(\"Correlation of %s Odds Among Betting Companies\" % name, fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try fitting a KNN classifier for B365 first using raw probabilities......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# slice out probablities for each betting company\n",
    "X_b365 = bets_percentage.rdiv(1).iloc[:,:3]\n",
    "X_bw = bets_percentage.rdiv(1).iloc[:,3:6]\n",
    "X_iw = bets_percentage.rdiv(1).iloc[:,6:9]\n",
    "X_lb = bets_percentage.rdiv(1).iloc[:,9:12]\n",
    "X_wh = bets_percentage.rdiv(1).iloc[:,12:15]\n",
    "X_vc = bets_percentage.rdiv(1).iloc[:,15:18]\n",
    "X_all = bets_percentage.rdiv(1)\n",
    "\n",
    "X_comb = [X_b365, X_bw, X_iw, X_lb, X_wh, X_vc, X_all]\n",
    "\n",
    "# the target classes\n",
    "y = cleaned_bets['result'] # actual match outcomes\n",
    "odds_company = ['b365', 'bw', 'iw', 'lb', 'wh', 'sj', 'vc', 'all']\n",
    "\n",
    "cv_mean_knn = np.ones(7)\n",
    "\n",
    "j=0\n",
    "\n",
    "for X in X_comb:\n",
    "        for i in range(1,301):\n",
    "            \n",
    "            cv_score = []\n",
    "        \n",
    "            # split into train and test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "            # instantiate learning model (k = 11)\n",
    "            knn = KNeighborsClassifier(n_neighbors=11, weights='uniform')\n",
    "    \n",
    "            # fitting the model\n",
    "            knn.fit(X_train, y_train)\n",
    "\n",
    "            # predict the response\n",
    "            # pred = knn.predict(X_test)\n",
    "            # print(accuracy_score(y_test, pred)) \n",
    "            scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "            cv_score.append(scores.mean())\n",
    "        cv_mean_knn[j] = np.mean(cv_score)\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48484389 0.48822134 0.48103912 0.48671815 0.47958923 0.48259187\n",
      " 0.48451224]\n"
     ]
    }
   ],
   "source": [
    "print(cv_mean_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try Naive Bayes........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "cv_mean_nb = np.ones(7)\n",
    "\n",
    "j=0\n",
    "\n",
    "for X in X_comb:\n",
    "        for i in range(1,301):\n",
    "            \n",
    "            cv_score = []\n",
    "        \n",
    "            # split into train and test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "            # instantiate learning model (k = 11)\n",
    "            GNB = GaussianNB()\n",
    "    \n",
    "            # fitting the model\n",
    "            GNB.fit(X_train, y_train)\n",
    "\n",
    "            # predict the response\n",
    "            # pred = knn.predict(X_test)\n",
    "            # print(accuracy_score(y_test, pred)) \n",
    "            scores = cross_val_score(GNB, X_train, y_train, cv=10, scoring='accuracy')\n",
    "            cv_score.append(scores.mean())\n",
    "        cv_mean_nb[j] = np.mean(cv_score)\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50596145 0.50788233 0.49981036 0.50736724 0.50478609 0.51215721\n",
      " 0.47207731]\n"
     ]
    }
   ],
   "source": [
    "print(cv_mean_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now QDA....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "cv_mean_qda = np.ones(7)\n",
    "\n",
    "j=0\n",
    "\n",
    "for X in X_comb:\n",
    "        for i in range(1,301):\n",
    "            \n",
    "            cv_score = []\n",
    "        \n",
    "            # split into train and test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "            # instantiate learning model (k = 11)\n",
    "            qda = QDA()\n",
    "    \n",
    "            # fitting the model\n",
    "            qda.fit(X_train, y_train)\n",
    "\n",
    "            # predict the response\n",
    "            # pred = knn.predict(X_test)\n",
    "            # print(accuracy_score(y_test, pred)) \n",
    "            scores = cross_val_score(qda, X_train, y_train, cv=10, scoring='accuracy')\n",
    "            cv_score.append(scores.mean())\n",
    "        cv_mean_qda[j] = np.mean(cv_score)\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52538675 0.52688683 0.52379154 0.52557523 0.5211165  0.52548128\n",
      " 0.50356759]\n"
     ]
    }
   ],
   "source": [
    "print(cv_mean_qda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now LDA....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "C:\\Users\\leeji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "cv_mean_lda = np.ones(7)\n",
    "\n",
    "j=0\n",
    "\n",
    "for X in X_comb:\n",
    "        for i in range(1,301):\n",
    "            \n",
    "            cv_score = []\n",
    "        \n",
    "            # split into train and test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "            # instantiate learning model (k = 11)\n",
    "            lda = LDA()\n",
    "    \n",
    "            # fitting the model\n",
    "            lda.fit(X_train, y_train)\n",
    "\n",
    "            # predict the response\n",
    "            # pred = knn.predict(X_test)\n",
    "            # print(accuracy_score(y_test, pred)) \n",
    "            scores = cross_val_score(lda, X_train, y_train, cv=10, scoring='accuracy')\n",
    "            cv_score.append(scores.mean())\n",
    "        cv_mean_lda[j] = np.mean(cv_score)\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53195716 0.53148638 0.52928201 0.53214566 0.52956326 0.53163027\n",
      " 0.53270699]\n"
     ]
    }
   ],
   "source": [
    "print(cv_mean_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-85bb8913cc64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcv_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcv_mean_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_mean_nb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_mean_lda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_mean_qda\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "cv_scores = [cv_mean_knn, cv_mean_nb, cv_mean_lda, cv_mean_qda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-76a381e1bfcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# library packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import neighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "### plot decision boundaries\n",
    "\n",
    "# Build classifiers\n",
    "gnb = GaussianNB()\n",
    "qda = QDA()\n",
    "lda = LDA()\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 11)\n",
    "\n",
    "# Train and Evaluate\n",
    "names = ['GaussianNB', 'QDA' , 'LDA', 'kNN']\n",
    "classifiers = [gnb, qda , lda, knn]\n",
    "\n",
    "# create color maps\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_light = ListedColormap(['#FFBBBB', '#BBFFBB', '#BBBBFF'])\n",
    "cmap_bold = ListedColormap(['#CC0000', '#00AA00', '#0000CC'])\n",
    "\n",
    "h = 0.1  # step size in the mesh\n",
    "\n",
    "for ind in [0,1]:\n",
    "    x_min, x_max = X_test[ind][:,0].min()-1, X_test[ind][:,0].max()+1\n",
    "    y_min, y_max = X_test[ind][:,1].min()-1, X_test[ind][:,1].max()+1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    print(xx.shape, yy.shape)\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    labels = ['gnb', 'qda']\n",
    "    models = [gnb, qda]\n",
    "    plt.figure(figsize=(12,5))\n",
    "    counter=1\n",
    "    for label, clf in zip(labels, models):\n",
    "        plt.subplot(1,2,counter)\n",
    "        counter+=1\n",
    "        clf.fit(X_train[ind], y_train[ind])\n",
    "        yhat = clf.predict(X_test[ind])\n",
    "\n",
    "        ZZ = clf.predict(grid)\n",
    "        ZZ = ZZ.reshape(xx.shape) # 2-D grid layout\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each grid point\n",
    "        plt.pcolormesh(xx, yy, ZZ, cmap=cmap_light)\n",
    "\n",
    "        # Plot also the training points\n",
    "        plt.scatter(X_test[ind][:,0], X_test[ind][:,1], c=yhat, cmap=cmap_bold)\n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.title(label + '\\nError Rate = {:0.2f}%'.format((yhat != y_test[ind]).sum() * 100 / len(y_test[ind])))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
